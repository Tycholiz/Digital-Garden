<h1 id="strategies"><a aria-hidden="true" class="anchor-heading" href="#strategies"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Strategies</h1>
<h3 id="approaches-to-common-problems-arising-because-of-a-distributed-system"><a aria-hidden="true" class="anchor-heading" href="#approaches-to-common-problems-arising-because-of-a-distributed-system"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Approaches to common problems arising because of a distributed system</h3>
<h4 id="key-generation-system"><a aria-hidden="true" class="anchor-heading" href="#key-generation-system"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Key Generation System</h4>
<p>Imagine we were making a URL shortener like TinyURL. As a database solution, we opt for a NoSQL approach key-value store, where each key is the shortform URL, and the value is the longform URL.</p>
<h5 id="naive-approach"><a aria-hidden="true" class="anchor-heading" href="#naive-approach"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Naive approach</h5>
<p>Each time a write request is made (ie. user creates a new shortform URL), the application server generates a new random 6 character string, and attempts to insert it into the DB. If that key exists already, then it tries again, until there is no failure. This is naive because it involves a lot of back and forth between application server and database, and results in an unpredictable time complexity.</p>
<h5 id="smarter-approach"><a aria-hidden="true" class="anchor-heading" href="#smarter-approach"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Smarter approach</h5>
<p>Have a standalone Key Generation Service (KGS), which generates the random 6 character strings in advance and stores them in a separate database (the Key-DB). Whenever a user wants to generate a new TinyURL, we take a key from the Key-DB and use it. This takes out the worry of collision and duplications of keys.</p>
<p>The purpose of the 2 tables is to handle read concurrency issues. The problem we are trying to solve is to not give the same key to two servers (as we donâ€™t want two URLs to have the same short key)</p>
<p>In our Key-DB, we can have 2 tables to store the keys, for:</p>
<ol>
<li><code>unused_keys</code></li>
<li><code>used_keys</code></li>
</ol>
<p>The reason we have 2 tables is to solve read concurrency issues. We are trying to avoid a situation where we give the same key to two application servers. Since there is only 1 KGS in the system at a time, there are inherently no write concurrency issues.</p>
<p>The KGS can always keep some unused keys in memory, so that whenever a server needs them, it can provide them quickly. As soon as the KGS loads some keys in memory, it moves them from <code>unused_keys</code> to <code>used_keys</code>, so that we can ensure each server gets unique keys. It's true that if the KGS goes offline, all those keys will be lost (and will still exist in the <code>used_keys</code> table). This is ok, since there are such a large amount of keys anyway.</p>
<p>Since the KGS would be a single point of failure, we can have a standby replica, and whenever the primary server dies it can take over to generate and provide keys.</p>
<p><img src="/Digital-Garden/assets/images/2021-10-13-11-24-19.png"></p>