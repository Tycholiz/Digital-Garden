<h1 id="etl-pipeline">ETL Pipeline<a aria-hidden="true" class="anchor-heading icon-link" href="#etl-pipeline"></a></h1>
<p>Stands for <strong>Extract</strong>, <strong>Transform</strong>, <strong>Load</strong></p>
<p>The ETL Pipeline can be thought as a series of processes whose goal is to take data from some external source, transform it to fit our needs, then loading that transformed data into our own database. </p>
<ul>
<li>With this capability, we are able to enhance reporting, analysis and data synchronization.</li>
</ul>
<h3 id="extract">Extract<a aria-hidden="true" class="anchor-heading icon-link" href="#extract"></a></h3>
<ul>
<li>data might be extracted from business systems, APIs, data from physical sensors, marketing tools, transaction databases (eg. Stripe)</li>
</ul>
<h3 id="transform">Transform<a aria-hidden="true" class="anchor-heading icon-link" href="#transform"></a></h3>
<p>data is temporarily stored in at least one set of staging tables as part of the ETL process</p>
<h3 id="load">Load<a aria-hidden="true" class="anchor-heading icon-link" href="#load"></a></h3>
<p>the load phase doesn't have to be the end of the pipeline. Once the data has been successfully inserted into our database, it can trigger webhooks in other systems to perform more actions.</p>
<h2 id="implementations">Implementations<a aria-hidden="true" class="anchor-heading icon-link" href="#implementations"></a></h2>
<ul>
<li><a href="/notes/ulicRRwo3lSFzh3tMfWH9">Apache Flink</a></li>
</ul>
<hr>
<strong>Backlinks</strong>
<ul>
<li><a href="/notes/YxwqHEq2TsfL7ShAfW2Rw">Apache Hadoop</a></li>
<li><a href="/notes/3NfgHUUU25MfpnbtOJfr9">Data Warehouse</a></li>
</ul>