<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><title>Strategies</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="The Tech Digital Garden of Kyle Tycholiz"/><meta property="og:title" content="Strategies"/><meta property="og:description" content="The Tech Digital Garden of Kyle Tycholiz"/><meta property="og:url" content="https://tech.kyletycholiz.com/notes/wbs6c9snnonnyzm8vk2t4b9/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="3/12/2022"/><meta property="article:modified_time" content="7/25/2023"/><link rel="canonical" href="https://tech.kyletycholiz.com/notes/wbs6c9snnonnyzm8vk2t4b9/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/_next/static/css/8e7b7e4bce421c0a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8e7b7e4bce421c0a.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-3d209faeb64f2f97.js" defer=""></script><script src="/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/_next/static/chunks/main-104451f3d1a5c4bc.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6b338472289fe290.js" defer=""></script><script src="/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/_next/static/fo6gubzKP_KV9RZPhaoiQ/_buildManifest.js" defer=""></script><script src="/_next/static/fo6gubzKP_KV9RZPhaoiQ/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="strategies">Strategies<a aria-hidden="true" class="anchor-heading icon-link" href="#strategies"></a></h1>
<p>With multiple replicas, a question inevitably arises: how do we ensure that all the data gets copied to all the replicas? </p>
<ul>
<li>Naturally, every write to the database needs to be processed by every replica. Every replication strategy must ensure that the data is eventually the same in all replicas.</li>
</ul>
<h1 id="replication-strategies">Replication Strategies<a aria-hidden="true" class="anchor-heading icon-link" href="#replication-strategies"></a></h1>
<p>There are three main algorithms for replicating changes between nodes: </p>
<ul>
<li>single-leader </li>
<li>multi-leader</li>
<li>leaderless</li>
</ul>
<h2 id="single-leader-based-replication">Single-Leader based replication<a aria-hidden="true" class="anchor-heading icon-link" href="#single-leader-based-replication"></a></h2>
<ul>
<li>a.k.a <em>active/passive</em> or <em>master–slave replication</em></li>
<li>this mode of replication is widespread, and is built into <a href="/notes/ULkfbL9WpktbVYnzhl6Jw">postgres</a>, <a href="/notes/WQoMTf6VXBaxCgksXAVsj">Kafka</a>, <a href="/notes/zhhxcjZUHdU8uRLwGb9Zh">Mongo</a> etc.</li>
</ul>
<p>There are no conflict resolution issues to deal with in single-leader replication.</p>
<h3 id="approach">Approach<a aria-hidden="true" class="anchor-heading icon-link" href="#approach"></a></h3>
<ol>
<li>A client wants to write to the database. It sends its request to the leader, which writes to its own local storage.</li>
<li>When the leader writes to its local storage, it also sends the data change to all of its followers as part of a replication log (or change stream)</li>
<li>Each follower applies all of the writes from the replication log</li>
<li>Now, the leader and any of the followers can fulfill read requests.</li>
</ol>
<p>Since we can only write to the leader, but can read from any follower, this method works well in the web, where there are many more reads than writes.</p>
<h3 id="adding-new-followers">Adding new followers<a aria-hidden="true" class="anchor-heading icon-link" href="#adding-new-followers"></a></h3>
<ol>
<li>Take a consistent snapshot of the leader’s database at some point in time.</li>
<li>Copy the snapshot to the new follower node.</li>
<li>The follower connects to the leader and requests all the data changes that have happened since the snapshot was taken. 
<ul>
<li>This requires that the snapshot is associated with an exact position in the leader’s replication log. 
<ul>
<li>That position is called the <em>log sequence number</em> in Postgres.</li>
</ul>
</li>
</ul>
</li>
<li>When the follower has processed the backlog of data changes since the snapshot, we say it has caught up. It can now continue to process data changes from the leader as they happen.</li>
</ol>
<h3 id="failover">Failover<a aria-hidden="true" class="anchor-heading icon-link" href="#failover"></a></h3>
<p>On its local disk, each follower keeps a log of the data changes it has received from the leader. If a follower crashes and is restarted, or if the network between the leader and the follower is temporarily interrupted, the follower can recover quite easily. It simply needs to connect to the leader and request all the data changes that occurred during the time when the follower was disconnected</p>
<p>However, things are much trickier if the leader fails. Three things must happen (this process is called <em>failover</em>): </p>
<ol>
<li>one of the followers needs to be promoted to be the new leader. </li>
<li>clients need to update who they send their write requests to. </li>
<li>the remaining followers must be aware of who the new leader is.</li>
</ol>
<h4 id="failover-comes-with-some-wrinkles">Failover comes with some wrinkles:<a aria-hidden="true" class="anchor-heading icon-link" href="#failover-comes-with-some-wrinkles"></a></h4>
<ul>
<li>If asynchronous replication is used, the new leader may not have received all the writes from the old leader before it failed. If the former leader rejoins the cluster after a new leader has been chosen, what should happen to those writes? The new leader may have received conflicting writes in the meantime. The most common solution is for the old leader’s unreplicated writes to simply be discarded, which may violate clients’ durability expectations.</li>
<li>what if our leader database has an incrementing strategy for assigning IDs? Now, when the leader fails, unless the follower-to-be-leader is perfectly up to date, it will start assigning IDs that have already been assigned by the original leader.</li>
<li>we could wind up in a situation where two former followers both think they are the new leader (a situation called <em>split brain</em>)</li>
</ul>
<h3 id="implementing-a-replication-log">Implementing a Replication Log<a aria-hidden="true" class="anchor-heading icon-link" href="#implementing-a-replication-log"></a></h3>
<p>a replication log is a stream of database write events, produced by the leader as it processes transactions. The followers apply that stream of writes to their own copy of the database and thus end up with an accurate copy of the same data. The events in the replication log describe the data changes that occurred.</p>
<p>There are several different replication methods</p>
<ul>
<li>statement-based replication</li>
<li>WAL shipping</li>
</ul>
<h4 id="statement-based-replication">Statement-based replication<a aria-hidden="true" class="anchor-heading icon-link" href="#statement-based-replication"></a></h4>
<p>The leader logs every write request (e.g. INSERT, UPDATE, DELETE) that it executes and sends that statement log to its followers. Then each follower executes those commands as if they had come from the client directly.</p>
<p>Drawbacks:</p>
<ul>
<li>what happens with non-deterministic functions like <code>now()</code> and <code>rand()</code>?</li>
<li>if IDs are incremented, or if a statement depends on existing data, they must be executed in the exact same order on each replica</li>
<li>statements that have side effects (e.g. <a href="/notes/nsG0iCcMBCUc5J4mxTA8T">triggers</a>, <a href="/notes/oAGY63H6XOxPhHOX6pqjP">functions</a>) may result in different side-effects on each replica, unless they are deterministic.</li>
</ul>
<h4 id="write-ahead-log-wal-shipping">Write-ahead log (WAL) shipping<a aria-hidden="true" class="anchor-heading icon-link" href="#write-ahead-log-wal-shipping"></a></h4>
<p>In the normal order of business, every write is appended to a <a href="/notes/iVqY5tKOzlWVVRzOqOED5#write-ahead-logging-wal1">WAL</a>.</p>
<ul>
<li>instead of the leader simply writing the WAL to disk, it also sends it to all followers. This allows each follower to build a copy of the exact same data structures as found on the leader.</li>
<li>used in <a href="/notes/ULkfbL9WpktbVYnzhl6Jw">Postgres</a></li>
</ul>
<p>Drawback:</p>
<ul>
<li>the log describes the data on a very low level: a WAL contains details of which bytes were changed in which disk blocks, meaning replication is closely coupled to the storage engine (A different strategy using a <em>logical log</em> exists to solve this issue of coupling. This is <a href="https://www.postgresql.org/docs/10/logical-replication.html">supported by Postgres</a>).
<ul>
<li>If the database changes its storage format from one version to another, it is typically not possible to run different versions of the database software on the leader and the followers.</li>
<li>the only way to solve this (without downtime) is to upgrade all the followers, then perform a <em>failover</em>, resulting in one of the followers becoming the new leader. For this to work, the replication protocol must support version mismatching like this. Typically, WAL shipping doesn't allow this.</li>
</ul>
</li>
</ul>
<h2 id="multi-leader-based-replication">Multi-Leader based replication<a aria-hidden="true" class="anchor-heading icon-link" href="#multi-leader-based-replication"></a></h2>
<p>In this setup, replication still happens in the same way as <em>single-leader replication</em>: each node that processes a write must forward that data change to all the other nodes.</p>
<ul>
<li>The key difference is that each leader simultaneously acts as a follower to the other leaders.</li>
</ul>
<p>Due to the added complexity of setup, we use this configuration mainly when we have multiple datacenters. In this case, each datacenter would have its own leader.</p>
<ul>
<li>each datacenter implements single-leader replication, but between datacenters, each leader replicates its changes to the leaders in other datacenters.</li>
</ul>
<p>With this replication strategy, each datacenter can continue operating independently of the others</p>
<p>BDR is a Postgres tool for implementing this replication strategy.</p>
<p>anal: consider an <a href="/notes/pFKPROeJ3nFTzivRYIL9W">offline-first</a> application like a calendar. We can have a calendar on our laptop, tablet and mobile, and each acts as a leader (ie. it accepts write requests). But we also need some way to sync data between devices (ie. an asynchronous multi-leader replication process)</p>
<ul>
<li>From an architectural point of view, each device is a datacenter with extremely unreliable connection between them (because of the offline-first nature)</li>
</ul>
<h3 id="write-conflicts">Write Conflicts<a aria-hidden="true" class="anchor-heading icon-link" href="#write-conflicts"></a></h3>
<p>This strategy has a major downside: the same data may be concurrently modified in two different datacenters, requiring us to resolve those write conflicts.</p>
<ul>
<li>because of this, the multi-leader replication strategy is dangerous and should be avoided if possible.</li>
<li>write conflicts don't occur in single-leader replication, since writes are applied sequentially.
<ul>
<li>either the database would lock and wait for the first data modification to be written, or the second transaction would simply fail and require the user to retry the write.</li>
</ul>
</li>
</ul>
<p>In multi-leader, if each follower simply applied writes in the order that it saw them, the database would end up in an inconsistent state. Conflicts must be solved in a convergent way, rather than sequential.</p>
<p>conflict resolution usually applies at the level of an individual row or document, not for an entire transaction</p>
<ul>
<li>Thus, if you have a transaction that atomically makes several different writes, each write is still considered separately for the purposes of conflict resolution.</li>
</ul>
<p>Consider that conflicts don't necessarily have to be about writing different data to the same row. What if we had a meeting room booking system, and 2 different people booked the same room (which occurred because they each wrote to their own respective leaders)</p>
<p>In the event of write conflicts, there are a few strategies to resolve them:</p>
<ul>
<li>out of the contenders, designate some field value to be the determination factor. This could be a <code>createdAt</code> timestamp (we simply take the latest one), or we might assign each write a unique UUID. In the case of conflict, we simply accept the one with the highest ID.
<ul>
<li>this approach is popular, but it is naturally prone to data loss.</li>
</ul>
</li>
<li>give each replica a unique ID, and pre-designate replicas with the higher ID as the winner.
<ul>
<li>also implies data loss.</li>
</ul>
</li>
<li>merge the values together.
<ul>
<li>if we're talking about an object, we might be able to do this cleanly. But if we're talking a string, we might have to concatenate them.</li>
</ul>
</li>
<li>record the conflict in a separate data structure that preserves all information, and write application code that resolves the conflict at some later time (perhaps by prompting the user to handle the conflict).</li>
<li>custom logic (most multi-leader replication tools allow us to write application code to implement custom conflict-resolution logic). This code gets executed on either read or write.
<ul>
<li><em>on write</em> - As soon as the database system detects a conflict in the log of replicated changes, it calls the conflict handler.</li>
<li><em>on read</em> - When a conflict is detected, all the conflicting writes are stored. The next time the data is read, these multiple versions of the data are returned to the applica‐ tion. The application may prompt the user or automatically resolve the conflict, and write the result back to the database.
<ul>
<li>this is how CouchDB works.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="leaderless-replication">Leaderless Replication<a aria-hidden="true" class="anchor-heading icon-link" href="#leaderless-replication"></a></h2>
<p>In a leaderless replication scheme, any replica can accept writes from clients directly.</p>
<p>General replication then happens in one of two ways:</p>
<ol>
<li>the client directly sends its writes to several replicas</li>
<li>a coordinator node does this on behalf of the client
<ul>
<li>Unlike a leader database, that coordinator does not enforce a particular ordering of writes.</li>
</ul>
</li>
</ol>
<p>Leaderless replication is also suitable for multi-datacenter operation, since it is designed to tolerate conflicting concurrent writes, network interruptions, and latency spikes.</p>
<p>Leaderless replication could be summarized as <em>"the database will do as much as it can, and if it runs into an error, it won’t undo something it has already done"</em>— so it’s the application’s responsibility to recover from errors</p>
<p>used by <a href="/notes/gEztUcJYazBs8J8k0gi7o">DynamoDB</a>, Cassandra, Riak, <a href="/notes/g7ulqi8no93ezeocbesc3ll">CouchDB</a></p>
<hr>
<h1 id="synchronous--asynchronous-replication">Synchronous / Asynchronous Replication<a aria-hidden="true" class="anchor-heading icon-link" href="#synchronous--asynchronous-replication"></a></h1>
<p>In relational databases, this is often a configurable option; other systems are often hardcoded to be either one or the other.</p>
<p>Whether a replication scheme is synchronous or asynchronous has a profound effect on the system behavior when there is a fault.</p>
<h2 id="synchronous">Synchronous<a aria-hidden="true" class="anchor-heading icon-link" href="#synchronous"></a></h2>
<p>In a synchronous flow, the leader will wait until the follower has confirmed that it received the write before reporting success to the user, and before making the write visible to other clients.</p>
<p>The advantage of synchronous replication is that the follower is guaranteed to have an up-to-date copy of the data that is consistent with the leader. If the leader sud‐ denly fails, we can be sure that the data is still available on the follower. The disad‐ vantage is that if the synchronous follower doesn’t respond (because it has crashed, or there is a network fault, or for any other reason), the write cannot be processed. The leader must block all writes and wait until the synchronous replica is available again.</p>
<ul>
<li>therefore, it is impractical for all followers to be synchronous: any one node outage would cause the whole system to grind to a halt.</li>
<li>In practice, if you enable synchronous replication on a database, it usually means that one of the followers is synchronous, and the others are asynchronous. If the synchronous follower becomes unavailable or slow, one of the asynchronous followers is made synchronous. This guarantees that you have an up-to-date copy of the data on at least two nodes: the leader and one synchronous follower.</li>
</ul>
<h2 id="asynchronous">Asynchronous<a aria-hidden="true" class="anchor-heading icon-link" href="#asynchronous"></a></h2>
<p>In an asynchronous flow, the leader sends the message, but doesn’t wait for a response from the follower.</p>
<p>Asynchronous replication can be fast when the system is running smoothly, but there are complications to consider when replication lag increases and servers fail.</p>
<ul>
<li>If a leader fails and you promote an asynchronously updated follower to be the new leader, recently committed data may be lost.</li>
</ul>
<p>Often, leader-based replication is configured to be completely asynchronous. </p>
<ul>
<li>In this case, if the leader fails and is not recoverable, any writes that have not yet been replicated to followers are lost. This means that a write is not guaranteed to be durable, even if it has been confirmed to the client. </li>
<li>However, a fully asynchronous configuration has the advantage that the leader can continue processing writes, even if all of its followers have fallen behind.</li>
</ul>
<p>if an application reads from an asynchronous follower, it may see outdated information if the follower has fallen behind</p>
<ul>
<li>if you run the same query on the leader and a follower at the same time, you may get different results, because not all writes have been reflected in the follower (due to <em>replication lag</em>). This is just a temporary state, since the followers will eventually catch up. This effect is known as <em>eventual consistency</em></li>
</ul>
<p>The value of asynchronous replication is gets higher:</p>
<ul>
<li>as the number of followers increases</li>
<li>as our followers get more geographically distributed.</li>
</ul>
<h3 id="consistency-models-for-dealing-with-replication-lag">Consistency models for dealing with replication lag<a aria-hidden="true" class="anchor-heading icon-link" href="#consistency-models-for-dealing-with-replication-lag"></a></h3>
<p>When implementing an asynchronous strategy, there are some things to be aware of. Depending on our application, we might not necessarily care too much. </p>
<ul>
<li>ex. in Facebook's newsfeed, it doesn't really matter if all the latest posts are actually there. As long as it's eventual, it's fine.</li>
</ul>
<h4 id="read-after-write-consistency">read-after-write consistency<a aria-hidden="true" class="anchor-heading icon-link" href="#read-after-write-consistency"></a></h4>
<p>What happens if a user performs some action that writes some data to the database (ie. to the leader node), but by the time the user goes to view that data in the UI, the replication of data hasn't taken place yet between the leader and the follower that is handing the GET request? We need a way of implementing read-after-write consistency.</p>
<p>There are different strategies to implement read-after-write consistency, depending on what we're doing:</p>
<ul>
<li>when user is reading data that they recently modified, allow them to read directly from the leader. The issue is that we need to know if data has been modified without first querying for it. Therefore, we can make a simple rule: if the data is modifiable by the user, read from the leader; otherwise, read from a follower.
<ul>
<li>ex. in a social media website, you can only edit your own information. Therefore, if you are querying for your own data, always read from the leader.</li>
</ul>
</li>
<li>track the time of the last update and, for one minute after the last update, make all reads from the leader. You could also monitor the replication lag on followers and pre‐ vent queries on any follower that is more than one minute behind the leader.</li>
<li>The client can remember the timestamp of its most recent write, then the system can ensure that the replica serving any reads for that user reflects updates at least until that timestamp. If a replica is not sufficiently up to date, either the read can be handled by another replica or the query can wait until the replica has caught up.</li>
</ul>
<h4 id="monotonic-reads">Monotonic reads<a aria-hidden="true" class="anchor-heading icon-link" href="#monotonic-reads"></a></h4>
<p>Imagine user1 writes a comment on a post. The leader node replicates it instantaneously to follower1, but experiences lag in replicating it to follower2. User2 then logs in and reads the data from follower1, so it sees the comment from user1. Then, User2 refreshes the page, but this time the data is read from follower2. Due to the lag, User2 no longer sees the comment from user1.</p>
<ul>
<li><em>Monotonic reads</em> is a guarantee that this anomaly doesn't happen.</li>
<li>we achieve this by making sure that each user always makes their reads from the same replica</li>
</ul>
<h4 id="consistent-prefix-reads">Consistent Prefix Reads<a aria-hidden="true" class="anchor-heading icon-link" href="#consistent-prefix-reads"></a></h4>
<p>Imagine user1 comments on a post saying "how is the weather in Chicago?", then user2 writes a comment in response "pretty good". Now, imagine that user3 sees this post with the comments (via the data provided from followers). The comment from user2 gets replicated with little lag, but the comment from user1 experiences a lot of lag. The result may be that user3 sees these comments out of order.</p>
<ul>
<li><em>Consistent prefix reads</em> is a guarantee that this anomaly doesn't happen.
<ul>
<li>This guarantee says that if a sequence of writes happens in a certain order, then anyone reading those writes will see them appear in the same order.</li>
</ul>
</li>
</ul>
<p>This is a particular problem in partitioned (<a href="/notes/nMxAwbzkQChlhX37Gih8a">sharded</a>) databases</p>
<ul>
<li>If the database always applies writes in the same order, this anomaly doesn't happen</li>
<li>But, in many distributed databases, different partitions operate independently, so there is no global ordering of writes: when a user reads from the database, they may see some parts of the database in an older state and some in a newer state.</li>
</ul>
<hr>
<h1 id="conflict-resolution-strategies">Conflict Resolution Strategies<a aria-hidden="true" class="anchor-heading icon-link" href="#conflict-resolution-strategies"></a></h1>
<h3 id="last-write-wins-lww">Last-Write Wins (LWW)<a aria-hidden="true" class="anchor-heading icon-link" href="#last-write-wins-lww"></a></h3>
<p>Widely used in both multi-leader replication and leaderless databases </p>
<p>Problems with LWW:</p>
<ul>
<li>Because of <a href="/notes/KtprYZi78o2XwFHC5vvcX">clock</a> drift between nodes, a node with a lagging clock is unable to overwrite values previously written by a node with a fast clock until the clock skew between the nodes has elapsed. This can cause arbitrary amounts of data to be silently dropped without ever alerting the application.</li>
<li>LWW cannot distinguish between writes that occurred sequentially in quick succession (e.g. client B’s increment definitely occurs after client A’s write) and writes that were truly concurrent (neither writer was aware of the other).</li>
</ul>
<hr>
<strong>Backlinks</strong>
<ul>
<li><a href="/notes/g7ulqi8no93ezeocbesc3ll">CouchDB</a></li>
<li><a href="/notes/gKVIPNGV7duiD0yRnld8J">Replication</a></li>
</ul></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#replication-strategies" title="Replication Strategies">Replication Strategies</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#single-leader-based-replication" title="Single-Leader based replication">Single-Leader based replication</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#approach" title="Approach">Approach</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#adding-new-followers" title="Adding new followers">Adding new followers</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#failover" title="Failover">Failover</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#failover-comes-with-some-wrinkles" title="Failover comes with some wrinkles:">Failover comes with some wrinkles:</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#implementing-a-replication-log" title="Implementing a Replication Log">Implementing a Replication Log</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#statement-based-replication" title="Statement-based replication">Statement-based replication</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#write-ahead-log-wal-shipping" title="Write-ahead log (WAL) shipping">Write-ahead log (WAL) shipping</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#multi-leader-based-replication" title="Multi-Leader based replication">Multi-Leader based replication</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#write-conflicts" title="Write Conflicts">Write Conflicts</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#leaderless-replication" title="Leaderless Replication">Leaderless Replication</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#synchronous--asynchronous-replication" title="Synchronous / Asynchronous Replication">Synchronous / Asynchronous Replication</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#synchronous" title="Synchronous">Synchronous</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#asynchronous" title="Asynchronous">Asynchronous</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#consistency-models-for-dealing-with-replication-lag" title="Consistency models for dealing with replication lag">Consistency models for dealing with replication lag</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#read-after-write-consistency" title="read-after-write consistency">read-after-write consistency</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#monotonic-reads" title="Monotonic reads">Monotonic reads</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#consistent-prefix-reads" title="Consistent Prefix Reads">Consistent Prefix Reads</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#conflict-resolution-strategies" title="Conflict Resolution Strategies">Conflict Resolution Strategies</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#last-write-wins-lww" title="Last-Write Wins (LWW)">Last-Write Wins (LWW)</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"wbs6c9snnonnyzm8vk2t4b9","title":"Strategies","desc":"","updated":1690257620914,"created":1647112592396,"custom":{},"fname":"db.distributed.replication.strategies","type":"note","vault":{"fsPath":"../main/tech","name":"tech"},"contentHash":"db7b7627ead8c16269713e73578ead3d","links":[{"type":"wiki","from":{"fname":"db.distributed.replication.strategies","id":"wbs6c9snnonnyzm8vk2t4b9","vaultName":"tech"},"value":"pg","alias":"postgres","position":{"start":{"line":13,"column":61,"offset":592},"end":{"line":13,"column":76,"offset":607},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"pg"}},{"type":"wiki","from":{"fname":"db.distributed.replication.strategies","id":"wbs6c9snnonnyzm8vk2t4b9","vaultName":"tech"},"value":"kafka","position":{"start":{"line":13,"column":78,"offset":609},"end":{"line":13,"column":87,"offset":618},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"kafka"}},{"type":"wiki","from":{"fname":"db.distributed.replication.strategies","id":"wbs6c9snnonnyzm8vk2t4b9","vaultName":"tech"},"value":"mongo","position":{"start":{"line":13,"column":89,"offset":620},"end":{"line":13,"column":98,"offset":629},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"mongo"}},{"type":"wiki","from":{"fname":"db.distributed.replication.strategies","id":"wbs6c9snnonnyzm8vk2t4b9","vaultName":"tech"},"value":"pg.lang.triggers","alias":"triggers","position":{"start":{"line":59,"column":43,"offset":4492},"end":{"line":59,"column":72,"offset":4521},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"pg.lang.triggers"}},{"type":"wiki","from":{"fname":"db.distributed.replication.strategies","id":"wbs6c9snnonnyzm8vk2t4b9","vaultName":"tech"},"value":"pg.lang.func.custom","alias":"functions","position":{"start":{"line":59,"column":74,"offset":4523},"end":{"line":59,"column":107,"offset":4556},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"pg.lang.func.custom"}},{"type":"wiki","from":{"fname":"db.distributed.replication.strategies","id":"wbs6c9snnonnyzm8vk2t4b9","vaultName":"tech"},"value":"db.acid.atomicity","alias":"WAL","position":{"start":{"line":62,"column":63,"offset":4742},"end":{"line":62,"column":114,"offset":4793},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"db.acid.atomicity","anchorHeader":"write-ahead-logging-wal,1"}},{"type":"wiki","from":{"fname":"db.distributed.replication.strategies","id":"wbs6c9snnonnyzm8vk2t4b9","vaultName":"tech"},"value":"pg","position":{"start":{"line":64,"column":11,"offset":4996},"end":{"line":64,"column":17,"offset":5002},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"pg"}},{"type":"wiki","from":{"fname":"db.distributed.replication.strategies","id":"wbs6c9snnonnyzm8vk2t4b9","vaultName":"tech"},"value":"general.arch.offline-first","alias":"offline-first","position":{"start":{"line":82,"column":19,"offset":6676},"end":{"line":82,"column":63,"offset":6720},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"general.arch.offline-first"}},{"type":"wiki","from":{"fname":"db.distributed.replication.strategies","id":"wbs6c9snnonnyzm8vk2t4b9","vaultName":"tech"},"value":"aws.svc.dynamo","alias":"DynamoDB","position":{"start":{"line":123,"column":9,"offset":10810},"end":{"line":123,"column":36,"offset":10837},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"aws.svc.dynamo"}},{"type":"wiki","from":{"fname":"db.distributed.replication.strategies","id":"wbs6c9snnonnyzm8vk2t4b9","vaultName":"tech"},"value":"couchdb","alias":"CouchDB","position":{"start":{"line":123,"column":55,"offset":10856},"end":{"line":123,"column":74,"offset":10875},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"couchdb"}},{"type":"wiki","from":{"fname":"db.distributed.replication.strategies","id":"wbs6c9snnonnyzm8vk2t4b9","vaultName":"tech"},"value":"db.distributed.partitioning.sharding","alias":"sharded","position":{"start":{"line":179,"column":46,"offset":17102},"end":{"line":179,"column":94,"offset":17150},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"db.distributed.partitioning.sharding"}},{"type":"wiki","from":{"fname":"db.distributed.replication.strategies","id":"wbs6c9snnonnyzm8vk2t4b9","vaultName":"tech"},"value":"hardware.cpu.clock","alias":"clock","position":{"start":{"line":190,"column":14,"offset":17666},"end":{"line":190,"column":42,"offset":17694},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"hardware.cpu.clock"}},{"from":{"fname":"couchdb","id":"g7ulqi8no93ezeocbesc3ll","vaultName":"tech"},"type":"backlink","position":{"start":{"line":30,"column":22,"offset":2177},"end":{"line":30,"column":124,"offset":2279},"indent":[]},"value":"db.distributed.replication.strategies"},{"from":{"fname":"db.distributed.replication","id":"gKVIPNGV7duiD0yRnld8J","vaultName":"tech"},"type":"backlink","position":{"start":{"line":8,"column":46,"offset":438},"end":{"line":8,"column":108,"offset":500},"indent":[]},"value":"db.distributed.replication.strategies"},{"from":{"fname":"db.distributed.replication","id":"gKVIPNGV7duiD0yRnld8J","vaultName":"tech"},"type":"backlink","position":{"start":{"line":32,"column":1,"offset":2033},"end":{"line":32,"column":42,"offset":2074},"indent":[]},"value":"db.distributed.replication.strategies"}],"anchors":{"replication-strategies":{"type":"header","text":"Replication Strategies","value":"replication-strategies","line":11,"column":0,"depth":1},"single-leader-based-replication":{"type":"header","text":"Single-Leader based replication","value":"single-leader-based-replication","line":17,"column":0,"depth":2},"approach":{"type":"header","text":"Approach","value":"approach","line":23,"column":0,"depth":3},"adding-new-followers":{"type":"header","text":"Adding new followers","value":"adding-new-followers","line":31,"column":0,"depth":3},"failover":{"type":"header","text":"Failover","value":"failover","line":39,"column":0,"depth":3},"failover-comes-with-some-wrinkles":{"type":"header","text":"Failover comes with some wrinkles:","value":"failover-comes-with-some-wrinkles","line":47,"column":0,"depth":4},"implementing-a-replication-log":{"type":"header","text":"Implementing a Replication Log","value":"implementing-a-replication-log","line":52,"column":0,"depth":3},"statement-based-replication":{"type":"header","text":"Statement-based replication","value":"statement-based-replication","line":59,"column":0,"depth":4},"write-ahead-log-wal-shipping":{"type":"header","text":"Write-ahead log (WAL) shipping","value":"write-ahead-log-wal-shipping","line":67,"column":0,"depth":4},"multi-leader-based-replication":{"type":"header","text":"Multi-Leader based replication","value":"multi-leader-based-replication","line":77,"column":0,"depth":2},"write-conflicts":{"type":"header","text":"Write Conflicts","value":"write-conflicts","line":91,"column":0,"depth":3},"leaderless-replication":{"type":"header","text":"Leaderless Replication","value":"leaderless-replication","line":117,"column":0,"depth":2},"synchronous--asynchronous-replication":{"type":"header","text":"Synchronous / Asynchronous Replication","value":"synchronous--asynchronous-replication","line":133,"column":0,"depth":1},"synchronous":{"type":"header","text":"Synchronous","value":"synchronous","line":138,"column":0,"depth":2},"asynchronous":{"type":"header","text":"Asynchronous","value":"asynchronous","line":145,"column":0,"depth":2},"consistency-models-for-dealing-with-replication-lag":{"type":"header","text":"Consistency models for dealing with replication lag","value":"consistency-models-for-dealing-with-replication-lag","line":162,"column":0,"depth":3},"read-after-write-consistency":{"type":"header","text":"read-after-write consistency","value":"read-after-write-consistency","line":166,"column":0,"depth":4},"monotonic-reads":{"type":"header","text":"Monotonic reads","value":"monotonic-reads","line":175,"column":0,"depth":4},"consistent-prefix-reads":{"type":"header","text":"Consistent Prefix Reads","value":"consistent-prefix-reads","line":180,"column":0,"depth":4},"conflict-resolution-strategies":{"type":"header","text":"Conflict Resolution Strategies","value":"conflict-resolution-strategies","line":191,"column":0,"depth":1},"last-write-wins-lww":{"type":"header","text":"Last-Write Wins (LWW)","value":"last-write-wins-lww","line":192,"column":0,"depth":3}},"children":[],"parent":"gKVIPNGV7duiD0yRnld8J","data":{}},"body":"\u003ch1 id=\"strategies\"\u003eStrategies\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#strategies\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eWith multiple replicas, a question inevitably arises: how do we ensure that all the data gets copied to all the replicas? \u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNaturally, every write to the database needs to be processed by every replica. Every replication strategy must ensure that the data is eventually the same in all replicas.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"replication-strategies\"\u003eReplication Strategies\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#replication-strategies\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eThere are three main algorithms for replicating changes between nodes: \u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003esingle-leader \u003c/li\u003e\n\u003cli\u003emulti-leader\u003c/li\u003e\n\u003cli\u003eleaderless\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"single-leader-based-replication\"\u003eSingle-Leader based replication\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#single-leader-based-replication\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003ea.k.a \u003cem\u003eactive/passive\u003c/em\u003e or \u003cem\u003emaster–slave replication\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003ethis mode of replication is widespread, and is built into \u003ca href=\"/notes/ULkfbL9WpktbVYnzhl6Jw\"\u003epostgres\u003c/a\u003e, \u003ca href=\"/notes/WQoMTf6VXBaxCgksXAVsj\"\u003eKafka\u003c/a\u003e, \u003ca href=\"/notes/zhhxcjZUHdU8uRLwGb9Zh\"\u003eMongo\u003c/a\u003e etc.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThere are no conflict resolution issues to deal with in single-leader replication.\u003c/p\u003e\n\u003ch3 id=\"approach\"\u003eApproach\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#approach\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eA client wants to write to the database. It sends its request to the leader, which writes to its own local storage.\u003c/li\u003e\n\u003cli\u003eWhen the leader writes to its local storage, it also sends the data change to all of its followers as part of a replication log (or change stream)\u003c/li\u003e\n\u003cli\u003eEach follower applies all of the writes from the replication log\u003c/li\u003e\n\u003cli\u003eNow, the leader and any of the followers can fulfill read requests.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eSince we can only write to the leader, but can read from any follower, this method works well in the web, where there are many more reads than writes.\u003c/p\u003e\n\u003ch3 id=\"adding-new-followers\"\u003eAdding new followers\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#adding-new-followers\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eTake a consistent snapshot of the leader’s database at some point in time.\u003c/li\u003e\n\u003cli\u003eCopy the snapshot to the new follower node.\u003c/li\u003e\n\u003cli\u003eThe follower connects to the leader and requests all the data changes that have happened since the snapshot was taken. \n\u003cul\u003e\n\u003cli\u003eThis requires that the snapshot is associated with an exact position in the leader’s replication log. \n\u003cul\u003e\n\u003cli\u003eThat position is called the \u003cem\u003elog sequence number\u003c/em\u003e in Postgres.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWhen the follower has processed the backlog of data changes since the snapshot, we say it has caught up. It can now continue to process data changes from the leader as they happen.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"failover\"\u003eFailover\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#failover\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eOn its local disk, each follower keeps a log of the data changes it has received from the leader. If a follower crashes and is restarted, or if the network between the leader and the follower is temporarily interrupted, the follower can recover quite easily. It simply needs to connect to the leader and request all the data changes that occurred during the time when the follower was disconnected\u003c/p\u003e\n\u003cp\u003eHowever, things are much trickier if the leader fails. Three things must happen (this process is called \u003cem\u003efailover\u003c/em\u003e): \u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eone of the followers needs to be promoted to be the new leader. \u003c/li\u003e\n\u003cli\u003eclients need to update who they send their write requests to. \u003c/li\u003e\n\u003cli\u003ethe remaining followers must be aware of who the new leader is.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4 id=\"failover-comes-with-some-wrinkles\"\u003eFailover comes with some wrinkles:\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#failover-comes-with-some-wrinkles\"\u003e\u003c/a\u003e\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eIf asynchronous replication is used, the new leader may not have received all the writes from the old leader before it failed. If the former leader rejoins the cluster after a new leader has been chosen, what should happen to those writes? The new leader may have received conflicting writes in the meantime. The most common solution is for the old leader’s unreplicated writes to simply be discarded, which may violate clients’ durability expectations.\u003c/li\u003e\n\u003cli\u003ewhat if our leader database has an incrementing strategy for assigning IDs? Now, when the leader fails, unless the follower-to-be-leader is perfectly up to date, it will start assigning IDs that have already been assigned by the original leader.\u003c/li\u003e\n\u003cli\u003ewe could wind up in a situation where two former followers both think they are the new leader (a situation called \u003cem\u003esplit brain\u003c/em\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"implementing-a-replication-log\"\u003eImplementing a Replication Log\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#implementing-a-replication-log\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003ea replication log is a stream of database write events, produced by the leader as it processes transactions. The followers apply that stream of writes to their own copy of the database and thus end up with an accurate copy of the same data. The events in the replication log describe the data changes that occurred.\u003c/p\u003e\n\u003cp\u003eThere are several different replication methods\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003estatement-based replication\u003c/li\u003e\n\u003cli\u003eWAL shipping\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"statement-based-replication\"\u003eStatement-based replication\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#statement-based-replication\"\u003e\u003c/a\u003e\u003c/h4\u003e\n\u003cp\u003eThe leader logs every write request (e.g. INSERT, UPDATE, DELETE) that it executes and sends that statement log to its followers. Then each follower executes those commands as if they had come from the client directly.\u003c/p\u003e\n\u003cp\u003eDrawbacks:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ewhat happens with non-deterministic functions like \u003ccode\u003enow()\u003c/code\u003e and \u003ccode\u003erand()\u003c/code\u003e?\u003c/li\u003e\n\u003cli\u003eif IDs are incremented, or if a statement depends on existing data, they must be executed in the exact same order on each replica\u003c/li\u003e\n\u003cli\u003estatements that have side effects (e.g. \u003ca href=\"/notes/nsG0iCcMBCUc5J4mxTA8T\"\u003etriggers\u003c/a\u003e, \u003ca href=\"/notes/oAGY63H6XOxPhHOX6pqjP\"\u003efunctions\u003c/a\u003e) may result in different side-effects on each replica, unless they are deterministic.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"write-ahead-log-wal-shipping\"\u003eWrite-ahead log (WAL) shipping\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#write-ahead-log-wal-shipping\"\u003e\u003c/a\u003e\u003c/h4\u003e\n\u003cp\u003eIn the normal order of business, every write is appended to a \u003ca href=\"/notes/iVqY5tKOzlWVVRzOqOED5#write-ahead-logging-wal1\"\u003eWAL\u003c/a\u003e.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003einstead of the leader simply writing the WAL to disk, it also sends it to all followers. This allows each follower to build a copy of the exact same data structures as found on the leader.\u003c/li\u003e\n\u003cli\u003eused in \u003ca href=\"/notes/ULkfbL9WpktbVYnzhl6Jw\"\u003ePostgres\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDrawback:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ethe log describes the data on a very low level: a WAL contains details of which bytes were changed in which disk blocks, meaning replication is closely coupled to the storage engine (A different strategy using a \u003cem\u003elogical log\u003c/em\u003e exists to solve this issue of coupling. This is \u003ca href=\"https://www.postgresql.org/docs/10/logical-replication.html\"\u003esupported by Postgres\u003c/a\u003e).\n\u003cul\u003e\n\u003cli\u003eIf the database changes its storage format from one version to another, it is typically not possible to run different versions of the database software on the leader and the followers.\u003c/li\u003e\n\u003cli\u003ethe only way to solve this (without downtime) is to upgrade all the followers, then perform a \u003cem\u003efailover\u003c/em\u003e, resulting in one of the followers becoming the new leader. For this to work, the replication protocol must support version mismatching like this. Typically, WAL shipping doesn't allow this.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"multi-leader-based-replication\"\u003eMulti-Leader based replication\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#multi-leader-based-replication\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eIn this setup, replication still happens in the same way as \u003cem\u003esingle-leader replication\u003c/em\u003e: each node that processes a write must forward that data change to all the other nodes.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe key difference is that each leader simultaneously acts as a follower to the other leaders.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDue to the added complexity of setup, we use this configuration mainly when we have multiple datacenters. In this case, each datacenter would have its own leader.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eeach datacenter implements single-leader replication, but between datacenters, each leader replicates its changes to the leaders in other datacenters.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWith this replication strategy, each datacenter can continue operating independently of the others\u003c/p\u003e\n\u003cp\u003eBDR is a Postgres tool for implementing this replication strategy.\u003c/p\u003e\n\u003cp\u003eanal: consider an \u003ca href=\"/notes/pFKPROeJ3nFTzivRYIL9W\"\u003eoffline-first\u003c/a\u003e application like a calendar. We can have a calendar on our laptop, tablet and mobile, and each acts as a leader (ie. it accepts write requests). But we also need some way to sync data between devices (ie. an asynchronous multi-leader replication process)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFrom an architectural point of view, each device is a datacenter with extremely unreliable connection between them (because of the offline-first nature)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"write-conflicts\"\u003eWrite Conflicts\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#write-conflicts\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eThis strategy has a major downside: the same data may be concurrently modified in two different datacenters, requiring us to resolve those write conflicts.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ebecause of this, the multi-leader replication strategy is dangerous and should be avoided if possible.\u003c/li\u003e\n\u003cli\u003ewrite conflicts don't occur in single-leader replication, since writes are applied sequentially.\n\u003cul\u003e\n\u003cli\u003eeither the database would lock and wait for the first data modification to be written, or the second transaction would simply fail and require the user to retry the write.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn multi-leader, if each follower simply applied writes in the order that it saw them, the database would end up in an inconsistent state. Conflicts must be solved in a convergent way, rather than sequential.\u003c/p\u003e\n\u003cp\u003econflict resolution usually applies at the level of an individual row or document, not for an entire transaction\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThus, if you have a transaction that atomically makes several different writes, each write is still considered separately for the purposes of conflict resolution.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eConsider that conflicts don't necessarily have to be about writing different data to the same row. What if we had a meeting room booking system, and 2 different people booked the same room (which occurred because they each wrote to their own respective leaders)\u003c/p\u003e\n\u003cp\u003eIn the event of write conflicts, there are a few strategies to resolve them:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eout of the contenders, designate some field value to be the determination factor. This could be a \u003ccode\u003ecreatedAt\u003c/code\u003e timestamp (we simply take the latest one), or we might assign each write a unique UUID. In the case of conflict, we simply accept the one with the highest ID.\n\u003cul\u003e\n\u003cli\u003ethis approach is popular, but it is naturally prone to data loss.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003egive each replica a unique ID, and pre-designate replicas with the higher ID as the winner.\n\u003cul\u003e\n\u003cli\u003ealso implies data loss.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003emerge the values together.\n\u003cul\u003e\n\u003cli\u003eif we're talking about an object, we might be able to do this cleanly. But if we're talking a string, we might have to concatenate them.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003erecord the conflict in a separate data structure that preserves all information, and write application code that resolves the conflict at some later time (perhaps by prompting the user to handle the conflict).\u003c/li\u003e\n\u003cli\u003ecustom logic (most multi-leader replication tools allow us to write application code to implement custom conflict-resolution logic). This code gets executed on either read or write.\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eon write\u003c/em\u003e - As soon as the database system detects a conflict in the log of replicated changes, it calls the conflict handler.\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eon read\u003c/em\u003e - When a conflict is detected, all the conflicting writes are stored. The next time the data is read, these multiple versions of the data are returned to the applica‐ tion. The application may prompt the user or automatically resolve the conflict, and write the result back to the database.\n\u003cul\u003e\n\u003cli\u003ethis is how CouchDB works.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"leaderless-replication\"\u003eLeaderless Replication\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#leaderless-replication\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eIn a leaderless replication scheme, any replica can accept writes from clients directly.\u003c/p\u003e\n\u003cp\u003eGeneral replication then happens in one of two ways:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ethe client directly sends its writes to several replicas\u003c/li\u003e\n\u003cli\u003ea coordinator node does this on behalf of the client\n\u003cul\u003e\n\u003cli\u003eUnlike a leader database, that coordinator does not enforce a particular ordering of writes.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eLeaderless replication is also suitable for multi-datacenter operation, since it is designed to tolerate conflicting concurrent writes, network interruptions, and latency spikes.\u003c/p\u003e\n\u003cp\u003eLeaderless replication could be summarized as \u003cem\u003e\"the database will do as much as it can, and if it runs into an error, it won’t undo something it has already done\"\u003c/em\u003e— so it’s the application’s responsibility to recover from errors\u003c/p\u003e\n\u003cp\u003eused by \u003ca href=\"/notes/gEztUcJYazBs8J8k0gi7o\"\u003eDynamoDB\u003c/a\u003e, Cassandra, Riak, \u003ca href=\"/notes/g7ulqi8no93ezeocbesc3ll\"\u003eCouchDB\u003c/a\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch1 id=\"synchronous--asynchronous-replication\"\u003eSynchronous / Asynchronous Replication\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#synchronous--asynchronous-replication\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eIn relational databases, this is often a configurable option; other systems are often hardcoded to be either one or the other.\u003c/p\u003e\n\u003cp\u003eWhether a replication scheme is synchronous or asynchronous has a profound effect on the system behavior when there is a fault.\u003c/p\u003e\n\u003ch2 id=\"synchronous\"\u003eSynchronous\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#synchronous\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eIn a synchronous flow, the leader will wait until the follower has confirmed that it received the write before reporting success to the user, and before making the write visible to other clients.\u003c/p\u003e\n\u003cp\u003eThe advantage of synchronous replication is that the follower is guaranteed to have an up-to-date copy of the data that is consistent with the leader. If the leader sud‐ denly fails, we can be sure that the data is still available on the follower. The disad‐ vantage is that if the synchronous follower doesn’t respond (because it has crashed, or there is a network fault, or for any other reason), the write cannot be processed. The leader must block all writes and wait until the synchronous replica is available again.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003etherefore, it is impractical for all followers to be synchronous: any one node outage would cause the whole system to grind to a halt.\u003c/li\u003e\n\u003cli\u003eIn practice, if you enable synchronous replication on a database, it usually means that one of the followers is synchronous, and the others are asynchronous. If the synchronous follower becomes unavailable or slow, one of the asynchronous followers is made synchronous. This guarantees that you have an up-to-date copy of the data on at least two nodes: the leader and one synchronous follower.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"asynchronous\"\u003eAsynchronous\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#asynchronous\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eIn an asynchronous flow, the leader sends the message, but doesn’t wait for a response from the follower.\u003c/p\u003e\n\u003cp\u003eAsynchronous replication can be fast when the system is running smoothly, but there are complications to consider when replication lag increases and servers fail.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIf a leader fails and you promote an asynchronously updated follower to be the new leader, recently committed data may be lost.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOften, leader-based replication is configured to be completely asynchronous. \u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIn this case, if the leader fails and is not recoverable, any writes that have not yet been replicated to followers are lost. This means that a write is not guaranteed to be durable, even if it has been confirmed to the client. \u003c/li\u003e\n\u003cli\u003eHowever, a fully asynchronous configuration has the advantage that the leader can continue processing writes, even if all of its followers have fallen behind.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eif an application reads from an asynchronous follower, it may see outdated information if the follower has fallen behind\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eif you run the same query on the leader and a follower at the same time, you may get different results, because not all writes have been reflected in the follower (due to \u003cem\u003ereplication lag\u003c/em\u003e). This is just a temporary state, since the followers will eventually catch up. This effect is known as \u003cem\u003eeventual consistency\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe value of asynchronous replication is gets higher:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eas the number of followers increases\u003c/li\u003e\n\u003cli\u003eas our followers get more geographically distributed.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"consistency-models-for-dealing-with-replication-lag\"\u003eConsistency models for dealing with replication lag\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#consistency-models-for-dealing-with-replication-lag\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eWhen implementing an asynchronous strategy, there are some things to be aware of. Depending on our application, we might not necessarily care too much. \u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eex. in Facebook's newsfeed, it doesn't really matter if all the latest posts are actually there. As long as it's eventual, it's fine.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"read-after-write-consistency\"\u003eread-after-write consistency\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#read-after-write-consistency\"\u003e\u003c/a\u003e\u003c/h4\u003e\n\u003cp\u003eWhat happens if a user performs some action that writes some data to the database (ie. to the leader node), but by the time the user goes to view that data in the UI, the replication of data hasn't taken place yet between the leader and the follower that is handing the GET request? We need a way of implementing read-after-write consistency.\u003c/p\u003e\n\u003cp\u003eThere are different strategies to implement read-after-write consistency, depending on what we're doing:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ewhen user is reading data that they recently modified, allow them to read directly from the leader. The issue is that we need to know if data has been modified without first querying for it. Therefore, we can make a simple rule: if the data is modifiable by the user, read from the leader; otherwise, read from a follower.\n\u003cul\u003e\n\u003cli\u003eex. in a social media website, you can only edit your own information. Therefore, if you are querying for your own data, always read from the leader.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003etrack the time of the last update and, for one minute after the last update, make all reads from the leader. You could also monitor the replication lag on followers and pre‐ vent queries on any follower that is more than one minute behind the leader.\u003c/li\u003e\n\u003cli\u003eThe client can remember the timestamp of its most recent write, then the system can ensure that the replica serving any reads for that user reflects updates at least until that timestamp. If a replica is not sufficiently up to date, either the read can be handled by another replica or the query can wait until the replica has caught up.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"monotonic-reads\"\u003eMonotonic reads\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#monotonic-reads\"\u003e\u003c/a\u003e\u003c/h4\u003e\n\u003cp\u003eImagine user1 writes a comment on a post. The leader node replicates it instantaneously to follower1, but experiences lag in replicating it to follower2. User2 then logs in and reads the data from follower1, so it sees the comment from user1. Then, User2 refreshes the page, but this time the data is read from follower2. Due to the lag, User2 no longer sees the comment from user1.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eMonotonic reads\u003c/em\u003e is a guarantee that this anomaly doesn't happen.\u003c/li\u003e\n\u003cli\u003ewe achieve this by making sure that each user always makes their reads from the same replica\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"consistent-prefix-reads\"\u003eConsistent Prefix Reads\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#consistent-prefix-reads\"\u003e\u003c/a\u003e\u003c/h4\u003e\n\u003cp\u003eImagine user1 comments on a post saying \"how is the weather in Chicago?\", then user2 writes a comment in response \"pretty good\". Now, imagine that user3 sees this post with the comments (via the data provided from followers). The comment from user2 gets replicated with little lag, but the comment from user1 experiences a lot of lag. The result may be that user3 sees these comments out of order.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eConsistent prefix reads\u003c/em\u003e is a guarantee that this anomaly doesn't happen.\n\u003cul\u003e\n\u003cli\u003eThis guarantee says that if a sequence of writes happens in a certain order, then anyone reading those writes will see them appear in the same order.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis is a particular problem in partitioned (\u003ca href=\"/notes/nMxAwbzkQChlhX37Gih8a\"\u003esharded\u003c/a\u003e) databases\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIf the database always applies writes in the same order, this anomaly doesn't happen\u003c/li\u003e\n\u003cli\u003eBut, in many distributed databases, different partitions operate independently, so there is no global ordering of writes: when a user reads from the database, they may see some parts of the database in an older state and some in a newer state.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch1 id=\"conflict-resolution-strategies\"\u003eConflict Resolution Strategies\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#conflict-resolution-strategies\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003ch3 id=\"last-write-wins-lww\"\u003eLast-Write Wins (LWW)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#last-write-wins-lww\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eWidely used in both multi-leader replication and leaderless databases \u003c/p\u003e\n\u003cp\u003eProblems with LWW:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBecause of \u003ca href=\"/notes/KtprYZi78o2XwFHC5vvcX\"\u003eclock\u003c/a\u003e drift between nodes, a node with a lagging clock is unable to overwrite values previously written by a node with a fast clock until the clock skew between the nodes has elapsed. This can cause arbitrary amounts of data to be silently dropped without ever alerting the application.\u003c/li\u003e\n\u003cli\u003eLWW cannot distinguish between writes that occurred sequentially in quick succession (e.g. client B’s increment definitely occurs after client A’s write) and writes that were truly concurrent (neither writer was aware of the other).\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cstrong\u003eBacklinks\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/notes/g7ulqi8no93ezeocbesc3ll\"\u003eCouchDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/gKVIPNGV7duiD0yRnld8J\"\u003eReplication\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","noteIndex":{"id":"olZIVfSs2uLLr3BppFh4K","title":"Digital Garden","desc":"","updated":1674517603573,"created":1615482407722,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"../main/tech","name":"tech"},"contentHash":"effb007003ca6a91d7fd0c293e1d2436","links":[{"type":"wiki","from":{"fname":"root","id":"olZIVfSs2uLLr3BppFh4K","vaultName":"tech"},"value":"testing.method.unit","alias":"unit testing","position":{"start":{"line":18,"column":121,"offset":1146},"end":{"line":18,"column":157,"offset":1182},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"testing.method.unit"}},{"type":"wiki","from":{"fname":"root","id":"olZIVfSs2uLLr3BppFh4K","vaultName":"tech"},"value":"general.arch.microservice","alias":"microservices","position":{"start":{"line":18,"column":188,"offset":1213},"end":{"line":18,"column":231,"offset":1256},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"general.arch.microservice"}},{"type":"wiki","from":{"fname":"root","id":"olZIVfSs2uLLr3BppFh4K","vaultName":"tech"},"value":"paradigm.oop","alias":"OOP","position":{"start":{"line":36,"column":227,"offset":2718},"end":{"line":36,"column":247,"offset":2738},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"paradigm.oop"}}],"anchors":{"tags":{"type":"header","text":"Tags","value":"tags","line":46,"column":0,"depth":3},"resources":{"type":"header","text":"Resources","value":"resources","line":55,"column":0,"depth":2},"ue-unexamined-resources":{"type":"header","text":"UE (Unexamined) Resources","value":"ue-unexamined-resources","line":56,"column":0,"depth":3},"e-examined-resources":{"type":"header","text":"E (Examined) Resources","value":"e-examined-resources","line":59,"column":0,"depth":3},"resources-1":{"type":"header","text":"Resources","value":"resources-1","line":62,"column":0,"depth":3}},"children":["40ubf88tephzbdjte8cdsa0","zFMjbn3xihVNHjUIdZCD1","IK6NOKemuDjhfstJBovKL","ZaTr28eWk1DrXOEsc1YVb","Vi0WYVLZunVM9iR8XZJn3","ngAbg7gluvbt1bY1UIRsi","RCPPXSakm5TvKka8kOmVp","LIcuGYV0DDt1VWbvH6Sed","MPx8ykTP57I40WTZvTP7f","ZU5WmdTG1bHoE8RcmZXZG","jqWiyYJff92RjXuUQt9PQ","KihijM8OQvZ4pASkkhqzL","F9vyqvls3OBCujtukqKhy","k6jxm2b3edgkhbordpuz6v1","facc2b01-755a-409f-99f6-57bef2d1501f","bZumdyapJ2H0wWWOmJ45i","elqpgoe2r951si4xrhujppj","m5ov42Vm6mR7RQWTvl1NW","cw8cerc0cos8lh871oz8rtf","PZxxZ4iESzSlbbHJKxuAZ","UDu62Pa6BaRqlG8uGoMhy","u3zcndycwqessho5h6x0nz9","ZgCUp366YrF2Tyky2NT73","DVpVUmavSoVDA7UIlPzLX","nMCtMXVvjBsJk3iw1zoIO","ANfx9Z4a6ZA0uJuSHtbIJ","BkG557LKUYbH1DnxprEVT","1TaH8zDTM98FZ9SYaeXLM","02v7ymc144e5c4pv3edkud7","dc79799f-a55d-48ab-a8be-c48adb1b19c0","f6feef57-b8f5-451f-a09a-7b63f6a07183","4sz47Y0LKs1Si73rWtyyh","g7ulqi8no93ezeocbesc3ll","5a9fb1df-478e-4687-9be0-5cb97e61ec57","1374e9e9-1cbc-4e1f-b1ca-66b8569533dd","D8Z3rjXkSj2EOymXQXF4Z","np3c1ykvnjqv5xoombpfwqz","f529cc34-aba0-45ca-ad7e-02ddda318941","0zcauha3il2NqtxZazIo7","9bbd6f68-03b2-41f4-92e4-2ca313e8b450","5a2ab598-fa7e-4471-8bda-9f5831b679ae","uV6w4mZPoohWyZV4Xaad0","QHXEIyeZGIGMVi5Q52UWI","RgE0mZLaUjPftFPZsiAoe","mytCOts26Pidush65tdRW","fwUzxfLSPMH1eL8oBoLWx","wazdsda6h25x66edvfmeuiv","TbW7PM9bg1y5TGkiWwQ8b","xiSIDeEtIc8X0lpUQlppI","0jxgntiLNHWFuCbzqtFGF","GkdMprLUe4QQULBxmGN6V","4SYc6v5hxY5g6Ip6kjpwO","czi7ilt2i1uoqm1f2otbntj","fqVQpS9FBiXgKsZX3R3sJ","L5JUZlGAGvTxrsEBB7DY8","ttyri4pwfyn5lcx0vp9804o","TeTedoeS2LdHPR632eCpM","ulicRRwo3lSFzh3tMfWH9","p7d24vyb8m00ombzn34t50c","e65188a1-177e-4ab2-99f9-75f85d537621","fajYnbVhCRDi74xn0H30R","bArGdGwqo3iFkyKMyE7qR","4Dcp7gbEVoLLgfu7bXFai","5d700782-fb81-416e-83f9-5dd88260e350","zubgzhNFE6KlTgXcjTz6O","8lpdfWa0cbSq1XJQbcYcY","2psluywdc416t7vrql0m058","17I8ZksXvqCH1mRtZDjHp","kF916Ow84qpJJeMRkWMIo","tMLkLcrIHHBz56xVmBLkP","CSePBQ6q7qhowKESqVwt7","laZ4OfLhZNK1Kuy6GaWUr","z5IJblOknQhMzZ5QZh4ye","N36FHxfxzwJfxDY3miWyX","3bb25f58-2b50-4fa3-af55-48ea9f88a081","7x07qjgbitozdfszqzuy7ix","u93Rz4fEWGu6VBR30Zraf","9hjMHnKvYT4jLKvuDSXaV","qC5GxCZBmNb4Ip6c0kU8x","LgW7mTIALODoXc54B3p6S","UYPxfHBFWX7fb6hHU5bB6","74lYtC8NKpCzcyFOZTfR1","sEoBNAEuaTxwSmTXDonZt","dj0jr9mpvs62e2pkg3zc3yy","z8ie0xjogb6ht7gzowav5xr","qxSOd6SPN8qf9ZUojVFDX","WQoMTf6VXBaxCgksXAVsj","2Mw4XgfyCHXHNOX5yoCIY","qcdt2f7jo51muquo5r95dpo","0XJqmcdtcMZu66glBI5O8","lK8r8BXS4ThiUTe4xKIZe","93de42ca-53ea-460a-baa7-b9ec5c47cb1e","Rxs2jaGpdFzqYtP7lAJFJ","aO8W81Z0PyIb6Hs7nOHPW","lhzisalkebu4w5n01np07i0","7b5l4b6fi65n7sv9org5q1l","I01hENHnh8Tqu3Ok8sLzG","03o3n0hz9v9jtb7j889zpd4","evqsPNutOaZ8hcBCqxFQu","zhhxcjZUHdU8uRLwGb9Zh","G1aFACZB2ooWGMGwyd3ZW","YWy1C4tgoaCcw1m8JJsr7","Szj3o5iaNxPpesiCqwrbu","613syb18hb3v0u1ydvor7ru","XhvCDW3fIw6h6MhY5ticq","Q70g7SusFZBQXzkuQifv4","AzfWDH3wp7jFpL2EYxBcW","y0fwpZ9qMqirsLiFyOciU","ZF8xj8wwDUqKlrwTrCFZ1","tAJvhqhdfyZZa87QHq1TU","4hRmipi8lxpBLyzWu5JVB","iTg0C7QjvnmqBZeEigJNs","3babc3d2-79ae-470a-9c06-ab8bba2e684e","bF3UsMFya3fMeXWDspVov","ULkfbL9WpktbVYnzhl6Jw","PpNOO8JYWe6dM8wruSa7x","di40pCxDn7IiqE8lFdD46","rmW0mkerqV35I8QPji6lM","3IFIK1ByzeIxZCByryGLN","iImkYAKfkw3beAl6pLbDn","ecDe8DNWrkeQTwpTEvHje","i2it5id8qwtg27n4usg8bo1","Yqhdd9mSJGN7OJOeyoSD2","Ws5tah8tpeyn9tK8VBTg8","gWAg15uBJgkS2B0wcpMAa","l7V3v2ep1YdDCt7DOr7Ci","yM2PJBdqJnHpD63cPA6sW","qn0bre7eLbi3QMbCfWkUi","fSu0KxFL41IRouotqmbHs","0gtg24Mj1a1bQFPRGQNlO","7iQPBMltLPLbFEz2qbjPu","yoh4pwoXcfELInGKRdYf6","dCGCWXgAmiOZXbdULT1m6","jMavlje07sNa6hSEIE8WA","Xxm0JE4dKHxrQAaZfzvxD","nRb6Im4Kcmc2ZWE7K1jZ1","PAEBZCyFBZJyR7OoMZ41E","PQ6km8RgRCuyICBPOYz8f","x5tm1nfjzyawwzedy3yitgd","2bhftt8rGuxYu4pFgNqru","hjYIZpHQWuXfeEoGeJEKW","K2M9bQqVq2eQfm29eslKL","X8obW1iKwYsvNgKWGyCzy","yJwSC7hqYIezTFHf5i0Ev","c4Z7ETcOHUILRMH32Sfjw","qiR6dIu857b9M9kTqjOyK","fc2coz74cnfy5czzofx4h5x","Ku1OgHMhELajzo61Gx7ye","LUrfhDWo8wuwZu7CN9TV8","osu6JGOnvXJ5gt3tpqWZY","1a6173cd-cf13-4b34-a522-8350bf9a364f","S2sBltrPfd8a7ICuD7CuH","GLQ2pmkJUNUa93THBDVsD","md6xitz4exia2joa06i490b","oWCuBXOg6JWfZzjmKxmNl","jOmhZ8ovLYTPbpM1vqSDx","p9bov84s0isgkl1ysaw93kk","FraC6xzLy1ei91l1ICyc9","6ceBas2RE9Q4787GDngH7","734cd78d-0bc9-426b-803d-1efc84dfffe5","k4Bb09px6r0FxIRs49SXV","oaG3H1S9IUBO644nGZigu","Ka7agQJkUMRSWN0uFdkWK","si3z090WsiLasMhJBa1Az","hs6rwzt4mogiicoc4gcykbi","ljKAVERmdEiKLK9hXGKBm","zxt3lhonfdhglvijd17ua8c","dd7dopve1dudqkoibkqvti4","923tgifqf59ovv5yldtyi0a","vrjwp01goqw47fqctm4f4lo","c99gdmmppju3r1tth8cb2jx","z2pvn5qxdz84zgygqzxage8"],"parent":null,"data":{},"body":"This Dendron vault of tech knowledge is organized according to domains and their sub-domains, along with specific implementation of those domains.\n\nFor instance, Git itself is a domain. Sub-domains of Git would include things like `commit`,\n`tags`, `reflog` etc. implementations of each of those could be `cli`, `strat`\n(strategies), `inner`, and so on.\n\nThe goal of the wiki is to present data in a manner that is from the perspective\nof a querying user. Here, a user is a programmer wanting to get key information\nfrom a specific domain. For instance, if a user wants to use postgres functions\nand hasn't done them in a while, they should be able to query\n`postgres.functions` to see what information is available to them.\n\nThis wiki has been written with myself in mind. While learning each of these\ndomains, I have been sensitive to the \"aha\" moments and have noted down my\ninsights as they arose. I have refrained from capturing information that I\nconsidered obvious or otherwise non-beneficial to my own understanding.\n\nAs a result, I have allowed myself to use potentially arcane concepts to explain other ones. For example, in my note on [[unit testing|testing.method.unit]], I have made reference to the [[microservices|general.arch.microservice]] note. If these notes were made with the public in mind, this would be a very bad strategy, given that you'd have to understand microservices to be able to draw that same parallel that I've already drawn. Since these notes are written for myself, I have been fine with taking these liberties.\n\nWhat I hope to gain from this wiki is the ability to step away from any\ngiven domain for a long period of time, and be able to be passably useful for\nwhatever my goals are within a short period of time. Of course this is all\nvague sounding, and really depends on the domain along with the ends I am\ntrying to reach.\n\nTo achieve this, the system should be steadfast to:\n- be able to put information in relatively easily, without too much thought\n\trequired to its location. While location is important, Dendron makes it easy\n\tto relocate notes, if it becomes apparent that a different place makes more\n\tsense.\n- be able to extract the information that is needed, meaning there is a\n\thigh-degree in confidence in the location of the information. The idea is\n\tthat information loses a large amount of its value when it is unfindable.\n\tTherefore, a relatively strict ideology should be used when determining\n\twhere a piece of information belongs.\n\t- Some concepts might realistically belong to multiple domains. For instance, the concept of *access modifiers* can be found in both `C#` and `Typescript`. Therefore, this note should be abstracted to a common place, such as [[OOP|paradigm.oop]].\n\nThis Dendron vault is the sister component to the [General Second Brain](https://tech.kyletycholiz.com).\n\n### Tags\nThroughout the garden, I have made use of tags, which give semantic meaning to the pieces of information.\n\n- `ex.` - Denotes an *example* of the preceding piece of information\n- `spec:` - Specifies that the preceding information has some degree of *speculation* to it, and may not be 100% factual. Ideally this gets clarified over time as my understanding develops.\n- `anal:` - Denotes an *analogy* of the preceding information. Often I will attempt to link concepts to others that I have previously learned.\n- `mn:` - Denotes a *mnemonic*\n- `expl:` - Denotes an *explanation*\n\n## Resources\n### UE (Unexamined) Resources\nOften, I come across sources of information that I believe to be high-quality. They may be recommendations or found in some other way. No matter their origin, I may be in a position where I don't have the time to fully examine them (and properly extract notes), or I may not require the information at that moment in time. In cases like these, I will add reference to a section of the note called **UE Resources**. The idea is that in the future when I am ready to examine them, I have a list of resources that I can start with. This is an alternative strategy to compiling browser bookmarks, which I've found can quickly become untenable.\n\n### E (Examined) Resources\nOnce a resource has been thoroughly examined and has been mined for notes, it will be moved from *UE Resources* to *E Resources*. This is to indicate that (in my own estimation), there is nothing more to be gained from the resource that is not already in the note.\n\n### Resources\nThis heading is for inexhaustible resources. \n- A prime example would be a quality website that continually posts articles.  - Another example would be a tool, such as software that measures frequencies in a room to help acoustically treat it.\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"dendronVersion":"0.83.0","vaults":[{"fsPath":"../main/tech","name":"tech"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"The Tech Digital Garden of Kyle Tycholiz"},"github":{"cname":"tech.kyletycholiz.com","enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"master","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","enableMermaid":true,"siteUrl":"https://tech.kyletycholiz.com","duplicateNoteBehavior":{"action":"useVault","payload":["tech"]},"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"wbs6c9snnonnyzm8vk2t4b9"},"buildId":"fo6gubzKP_KV9RZPhaoiQ","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>